import os
from langchain import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.messages import HumanMessage
from langchain_community.chat_message_histories import ChatMessageHistory
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Set up the language model
model = ChatOpenAI(model="gpt-3.5-turbo")


def create_prompt_template():
    """
    Create a prompt template that defines the system's behavior and includes a placeholder for messages.

    Returns:
        ChatPromptTemplate: A template for formatting the prompts sent to the language model.
    """
    return ChatPromptTemplate.from_messages([
        {
            "role": "system",
            "content": "You are a helpful assistant. Answer all questions to the best of your ability.",
        },
        MessagesPlaceholder(variable_name="messages"),
    ])


def get_session_history(session_id: str):
    """
    Retrieve or create a message history object for a given session.

    Args:
        session_id (str): The unique identifier for the session.

    Returns:
        ChatMessageHistory: An object that stores the history of messages for the session.
    """
    if session_id not in store:
        store[session_id] = ChatMessageHistory()
    return store[session_id]


# Define prompt template
prompt = create_prompt_template()

# Create a store for message histories
store = {}

# Create a message history object for the session
session_id = "example_session"
message_history = RunnableWithMessageHistory(prompt | model, get_session_history(session_id))


def interact_with_model():
    """
    Interact with the language model using the defined prompt template and message history.

    Returns:
        AIMessage: The response generated by the language model.
    """
    response = message_history.invoke([
        HumanMessage(content="Hi! How can I assist you today?"),
    ])
    return response


# Example interaction with the model
response = interact_with_model()
print(response.content)


def interact_with_model():
    response = message_history.invoke([
        HumanMessage(content='Hi! How can I assist you today?'),
    ])
    return response


response = interact_with_model()
print(response.content)
